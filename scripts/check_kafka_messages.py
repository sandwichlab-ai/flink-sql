#!/usr/bin/env python3
"""
æ£€æŸ¥ Kafka Topic çš„æ¶ˆæ¯æ•°é‡ï¼ˆä½¿ç”¨ boto3 è°ƒç”¨ MSK APIï¼‰
"""
import boto3
import json
from datetime import datetime, timedelta

def check_kafka_lag():
    """æ£€æŸ¥ Kafka æ¶ˆè´¹è€… lag"""
    try:
        # ä½¿ç”¨ boto3 å®¢æˆ·ç«¯
        client = boto3.client('kafka', region_name='us-west-2')
        
        # è·å–é›†ç¾¤ ARNï¼ˆServerlessï¼‰
        # æ³¨æ„ï¼šMSK Serverless æ²¡æœ‰ç›´æ¥çš„ API æ¥æŸ¥çœ‹ consumer lag
        print("âš ï¸  MSK Serverless æ— æ³•ç›´æ¥é€šè¿‡ boto3 æŸ¥è¯¢æ¶ˆè´¹è€… lag")
        print("éœ€è¦ä½¿ç”¨ Kafka å®¢æˆ·ç«¯å·¥å…·ï¼ˆkafka-console-consumerï¼‰")
        
        # å»ºè®®ä½¿ç”¨ CloudWatch Metrics
        cloudwatch = boto3.client('cloudwatch', region_name='us-west-2')
        
        # æŸ¥è¯¢æœ€è¿‘ 10 åˆ†é’Ÿçš„ Flink åº”ç”¨ Records In æŒ‡æ ‡
        response = cloudwatch.get_metric_statistics(
            Namespace='AWS/KinesisAnalytics',
            MetricName='millisBehindLatest',
            Dimensions=[
                {
                    'Name': 'Application',
                    'Value': 'event-processor-dev'
                }
            ],
            StartTime=datetime.utcnow() - timedelta(minutes=10),
            EndTime=datetime.utcnow(),
            Period=60,
            Statistics=['Average', 'Maximum']
        )
        
        print("\nğŸ“Š Flink Application Lag (millisBehindLatest):")
        print(json.dumps(response['Datapoints'], indent=2, default=str))
        
        # æŸ¥è¯¢ Records In æŒ‡æ ‡
        response2 = cloudwatch.get_metric_statistics(
            Namespace='AWS/KinesisAnalytics',
            MetricName='numRecordsInPerSecond',
            Dimensions=[
                {
                    'Name': 'Application',
                    'Value': 'event-processor-dev'
                }
            ],
            StartTime=datetime.utcnow() - timedelta(minutes=10),
            EndTime=datetime.utcnow(),
            Period=60,
            Statistics=['Sum', 'Average']
        )
        
        print("\nğŸ“Š Flink Application Records In Per Second:")
        if response2['Datapoints']:
            for dp in sorted(response2['Datapoints'], key=lambda x: x['Timestamp'], reverse=True)[:10]:
                print(f"  {dp['Timestamp']}: {dp.get('Sum', 0):.2f} records/sec (avg: {dp.get('Average', 0):.2f})")
        else:
            print("  No data found")
            
    except Exception as e:
        print(f"âŒ Error: {e}")

if __name__ == "__main__":
    check_kafka_lag()
